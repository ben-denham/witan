{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Experiments\n",
    "\n",
    "The experiments below compare variants of our proposed Wɪᴛᴀɴ method to justify decisions in the design of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from witan_experiments import (is_cached,\n",
    "                               save_to_cache,\n",
    "                               load_from_cache,\n",
    "                               run_experiments)\n",
    "from witan_experiments.evaluation import (summarise_experiments,\n",
    "                                          build_metric_df,\n",
    "                                          display_metric_table)\n",
    "from witan_experiments.config import prepare_experiment_configs\n",
    "from witan_experiments.rule_seeders import BlankRS\n",
    "from witan_experiments.rule_generators import TrueRG, WitanRG\n",
    "from witan_experiments.labellers import SnorkelLblr\n",
    "from witan_experiments.models import AnnClf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruleset_generators = {\n",
    "    'Wɪᴛᴀɴ': WitanRG(),\n",
    "    'Core': WitanRG(a=False, o=1),\n",
    "    'Without ANDs': WitanRG(a=False),\n",
    "    'Without ORs': WitanRG(o=1),\n",
    "    'Without GE': WitanRG(ge=1),\n",
    "    'With feedback': WitanRG(f=True),\n",
    "    'Full supervision': TrueRG(),\n",
    "}\n",
    "\n",
    "base_config = dict(\n",
    "    rule_seeder=[BlankRS()],\n",
    "    rngseed=[1],\n",
    "    ruleset_generator=list(ruleset_generators.values()),\n",
    "    interaction_count=[25, 100],\n",
    "    labeller=[SnorkelLblr()],\n",
    "    classifier=[AnnClf()],\n",
    ")\n",
    "\n",
    "datasets = [\n",
    "    'imdb',\n",
    "    'bias_pa',\n",
    "    'bias_pt',\n",
    "    'bias_jp',\n",
    "    'bias_pp',\n",
    "    'amazon',\n",
    "    'yelp',\n",
    "    'plots',\n",
    "    'fakenews',\n",
    "    'binary_dbpedia',\n",
    "    'binary_agnews',\n",
    "    'airline_tweets',\n",
    "    'damage',\n",
    "    'spam',\n",
    "    'twentynews',\n",
    "    'dbpedia',\n",
    "    'agnews',\n",
    "    'nyttopics',\n",
    "]\n",
    "dataset_configs = {\n",
    "    dataset: [\n",
    "        *prepare_experiment_configs(**base_config, dataset_name=[dataset]),\n",
    "    ]\n",
    "    for dataset in datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_KEY = 'ablation-experiments'\n",
    "\n",
    "if not is_cached(CACHE_KEY):\n",
    "    dfs = []\n",
    "    for dataset, configs in dataset_configs.items():\n",
    "        print(f'\\nRunning experiments for: {dataset}')\n",
    "        dataset_results = run_experiments(\n",
    "            configs,\n",
    "            default_workers=2,\n",
    "            rule_workers=4,\n",
    "            continue_on_failure=False,\n",
    "        )\n",
    "        dfs.append(summarise_experiments(dataset_results, workers=8))\n",
    "    df = pd.concat(dfs)\n",
    "    save_to_cache(CACHE_KEY, df)\n",
    "\n",
    "df = load_from_cache(CACHE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df = df[df['interaction_count'].isin([25, 100])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df = build_metric_df(table_df, method='ruleset_generator', metric='test_macro_f1',\n",
    "                        labelled_methods=ruleset_generators)\n",
    "table = display_metric_table(f1_df, baseline_label='Wɪᴛᴀɴ')\n",
    "display(table)\n",
    "print(table.to_latex(multirow_align='t', convert_css=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
