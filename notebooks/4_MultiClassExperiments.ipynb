{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from witan_experiments import (is_cached,\n",
    "                               save_to_cache,\n",
    "                               load_from_cache,\n",
    "                               run_experiments)\n",
    "from witan_experiments.evaluation import (summarise_experiments,\n",
    "                                          metric_line_grid,\n",
    "                                          build_metric_df,\n",
    "                                          display_metric_table,\n",
    "                                          median_stds_df)\n",
    "from witan_experiments.config import prepare_experiment_configs\n",
    "from witan_experiments.rule_seeders import BlankRS, ClassSubsetAccRS\n",
    "from witan_experiments.rule_generators import (TrueRG,\n",
    "                                               WitanRG,\n",
    "                                               SnubaRG,\n",
    "                                               SemiSupervisedRG,\n",
    "                                               ActiveLearningRG,\n",
    "                                               CbiRG,\n",
    "                                               HdcRG)\n",
    "from witan_experiments.labellers import SnorkelLblr\n",
    "from witan_experiments.models import AnnClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruleset_generators = {\n",
    "    'Full supervision': TrueRG(),\n",
    "    'Wɪᴛᴀɴ': WitanRG(),\n",
    "    'Wɪᴛᴀɴ-Core': WitanRG(a=False, o=1),\n",
    "    'Snuba': SnubaRG(),\n",
    "    'HDC': HdcRG(),\n",
    "    'CBI': CbiRG(clf=AnnClf()),\n",
    "    'Semi-supervised': SemiSupervisedRG(),\n",
    "    'Active learning': ActiveLearningRG(clf=AnnClf(), init_count=0),\n",
    "}\n",
    "\n",
    "base_config = dict(\n",
    "    rule_seeder=[BlankRS()],\n",
    "    rngseed=[1, 2, 3, 4, 5],\n",
    "    interaction_count=[10, 25, 50, 100, 150, 200],\n",
    "    labeller=[SnorkelLblr()],\n",
    "    classifier=[AnnClf()],\n",
    ")\n",
    "\n",
    "parallel_configs = [\n",
    "    # Unseeded ruleset_generators that are not affected by rngseed\n",
    "    # (so we only need to execute them for the first rngseed)\n",
    "    {\n",
    "        **base_config,\n",
    "        **dict(\n",
    "            rngseed=base_config['rngseed'][:1],\n",
    "            ruleset_generator=[\n",
    "                ruleset_generators['Full supervision'],\n",
    "                ruleset_generators['Wɪᴛᴀɴ'],\n",
    "                ruleset_generators['Wɪᴛᴀɴ-Core'],\n",
    "                ruleset_generators['HDC'],\n",
    "            ],\n",
    "        ),\n",
    "    },\n",
    "    # Unseeded ruleset_generators\n",
    "    {\n",
    "        **base_config,\n",
    "        **dict(\n",
    "            ruleset_generator=[\n",
    "                ruleset_generators['Snuba'],\n",
    "                ruleset_generators['Semi-supervised'],\n",
    "                ruleset_generators['Active learning'],\n",
    "            ],\n",
    "        ),\n",
    "    },\n",
    "    # Seeded ruleset_generators\n",
    "    {\n",
    "        **base_config,\n",
    "        **dict(\n",
    "            rule_seeder=[ClassSubsetAccRS(c=2)],\n",
    "            ruleset_generator=[\n",
    "                ruleset_generators['CBI'],\n",
    "            ],\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "datasets = [\n",
    "    'twentynews',\n",
    "    'dbpedia',\n",
    "    'agnews',\n",
    "    'nyttopics',\n",
    "]\n",
    "dataset_configs = {\n",
    "    dataset: {\n",
    "        'parallel_configs': [\n",
    "            experiment_config\n",
    "            for parallel_config in parallel_configs\n",
    "            for experiment_config in prepare_experiment_configs(\n",
    "                **parallel_config,\n",
    "                dataset_name=[dataset],\n",
    "            )\n",
    "        ],\n",
    "    }\n",
    "    for dataset in datasets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_KEY = 'multiclass-experiments'\n",
    "CONTINUE_ON_FAILURE = False\n",
    "\n",
    "if not is_cached(CACHE_KEY):\n",
    "    dfs = []\n",
    "    for dataset, configs in dataset_configs.items():\n",
    "        print(f'\\nRunning experiments for: {dataset}')\n",
    "        dataset_parallel_results = run_experiments(\n",
    "            configs['parallel_configs'],\n",
    "            default_workers=3,\n",
    "            rule_workers=4,\n",
    "            continue_on_failure=CONTINUE_ON_FAILURE,\n",
    "        )\n",
    "        dfs.append(summarise_experiments(dataset_parallel_results, workers=8))\n",
    "    df = pd.concat(dfs)\n",
    "    save_to_cache(CACHE_KEY, df)\n",
    "\n",
    "df = load_from_cache(CACHE_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_label_suffix = '  '\n",
    "fig = metric_line_grid(\n",
    "    df,\n",
    "    metric='test_macro_f1',\n",
    "    facet_col='dataset_name',\n",
    "    ruleset_generators=ruleset_generators,\n",
    "    legend_y=1.08,\n",
    "    facet_row_spacing=0.15,\n",
    "    facet_col_spacing=0.1,\n",
    "    legend_label_suffix=legend_label_suffix,\n",
    "    category_orders={\n",
    "        'dataset_name': ['TWN', 'DBP', 'AGN', 'NYT'],\n",
    "        'ruleset_generator': [rg + legend_label_suffix for rg in ruleset_generators.keys()],\n",
    "    },\n",
    ")\n",
    "fig.write_image('plots/multi-f1-lines.svg')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_std_df = build_metric_df(df,\n",
    "                            method='ruleset_generator',\n",
    "                            metric='test_macro_f1',\n",
    "                            rngseed_agg='std',\n",
    "                            labelled_methods=ruleset_generators)\n",
    "display(display_metric_table(f1_std_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median Standard Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(median_stds_df(f1_std_df, datasets=datasets, ics=base_config['interaction_count']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
